# -*- coding: utf-8 -*-
"""Copy of TitanicSurvivalPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SXdreveQi0P2gqGAwgLvQ8TPcqQK2mCK
"""

# Commented out IPython magic to ensure Python compatibility.
#Import required modules
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification

from google.colab import files
up = files.upload()

df = pd.read_csv("titanicsurvival.csv")
#Check and convert TEXT Data to Binary
df.dtypes
df["Sex"] = df["Sex"].map({"male": 1, "female": 0}).astype(int)

#Check for null/NAN values
df["Age"].fillna(df["Age"].mean(), inplace=True)
df.columns[df.isna().any()]

X = df.iloc[:,:-1]
Y = df.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=3)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(x_train)
tr_x_train = ss.transform(x_train)
tr_x_test = ss.transform(x_test)

#Check whether Feature Scaling works fine
# ss_df = ss.transform(df)
# sns.pairplot(pd.DataFrame(ss_df))
# sns.pairplot(df)

from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB


rf_model = RandomForestClassifier()
lr_model = LogisticRegression()
ada_model = AdaBoostClassifier()
knn_model = KNeighborsClassifier()
nb_model = GaussianNB()
models_accuracy = []

models = [rf_model, lr_model, ada_model, knn_model, nb_model]
models_name = [str(i) for i in models]

pred = []
for model in models:
  model.fit(tr_x_train, y_train)
  y_train_pred = model.predict_proba(tr_x_train)
  train_accuracy = roc_auc_score(y_train, y_train_pred[:,-1]) * 100
  y_test_pred = model.predict_proba(tr_x_test)
  test_accuracy = roc_auc_score(y_test, y_test_pred[:,-1]) * 100
  print("Accuracy of Model: {} for train: {} %, test: {} %".format(str(model), train_accuracy, test_accuracy))
  models_accuracy.append(test_accuracy)
  pred.append(pd.Series(y_test_pred[:,-1]))

df_models_output = pd.concat(pred, axis=1)
df_models_output.columns = models_name
#Create a dataframe of all the model accuracy for a paricular sample
df_models_output["final_prediction"] = df_models_output.mean(axis=1)
print("Ensemble test roc-auc: {}".format(roc_auc_score(y_test, df_models_output["final_prediction"])))

from seaborn import colors
plt.bar(models_name, models_accuracy, color=list("rgbyg"))
plt.xlabel("Model Name", fontsize=14)
plt.ylabel("Accuracy", fontsize=14)
plt.title("ROC Accuracy Score of Various Classification models", fontsize=14)
for index, data in enumerate(models_accuracy):
  plt.text(x=index, y=data+0.5, s=f"{data.round(2)}%", ha="center", fontsize=12)
plt.ylim(70,90)
plt.xticks(rotation=60)
plt.show()

fpr, tpr, threshold = roc_curve(y_test, df_models_output["RandomForestClassifier()"])

plt.figure(figsize=(12,6))
plt.plot(fpr, tpr, "g-.v", mfc="r", mec="r", label="Random Forest Classifier")
plt.plot([0,1], [0,1], "b--o", label="Random Model")
plt.legend()
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Recursive Operation Characteristic(ROC) curve")
plt.show()

from sklearn.metrics import accuracy_score
accuracy_ls = []
for thres in threshold:
  y_pred = np.where(df_models_output["RandomForestClassifier()"].values > thres, 1, 0)
  accuracy_value = accuracy_score(y_pred, y_test)
  accuracy_ls.append(accuracy_value)

threshold_accuracy = pd.concat([pd.Series(threshold), pd.Series(accuracy_ls)], axis=1)
threshold_accuracy.columns = ["Threshold", "Accuracy"]
threshold_accuracy.sort_values(by="Accuracy", ascending=False, inplace=True)
threshold_accuracy.head()

"""##Accuracy values is max at threshold: 0.56"""

models = [rf_model, lr_model, ada_model, knn_model, nb_model]
models_name = [str(i) for i in models]

models_accuracy = []
for model in models:
  model.fit(tr_x_train, y_train)
  y_pred = model.predict(tr_x_test)
  test_accuracy = accuracy_score(y_test, y_pred) * 100
  print("Accuracy of Model: {} is {} %".format(str(model), test_accuracy))
  models_accuracy.append(test_accuracy)

plt.figure(figsize=(8,4), dpi=100)
plt.bar(models_name, models_accuracy, color=list("rgbyg"))
plt.ylim(70,85)
plt.xlabel("Model Name")
plt.ylabel("Accuracy")
plt.title("Accuracy of Models")
for index, data in enumerate(models_accuracy):
  plt.text(x=index, y=data+0.4, s=f"{data.round(2)}%", ha="center", fontsize=14)
plt.xticks(rotation=60)
plt.show()

"""#Since Accuracy for the dataset is more for RandormForestClassifier, we can use RF model"""

import pickle
pickle_out = open("classifier.pkl", "wb")
pickle.dump(rf_model, pickle_out)
pickle_out.close

